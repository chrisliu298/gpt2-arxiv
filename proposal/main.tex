\documentclass[runningheads]{llncs}
%
%\usepackage{subcaption}
\usepackage[margin=2.7cm]{geometry}

\usepackage{times}
\usepackage{latexsym}
\usepackage{graphicx}
\usepackage{tabularx}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{comment}
\usepackage{pgfplots,wrapfig}
\usepackage{color}
\usepackage{xcolor,colortbl}
\usepackage{enumitem}
\usepackage{amssymb,bbm}
\usepackage{array,subfigure,threeparttable}
\usepackage[toc,page]{appendix}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}

\newcommand{\ra}[1]{\renewcommand{\arraystretch}{#1}}
\newcolumntype{P}[1]{>{\centering\arraybackslash}p{#1}}
\newcolumntype{L}[1]{>{\raggedright\arraybackslash}p{#1}}
\pgfplotsset{compat=1.12}


\newcommand{\PP}{\mathbb P}
\newcommand{\BP}{\mathbf P}
\newcommand{\bp}{\mathbf p}
\newcommand{\CP}{\mathcal P}
\newcommand{\BR}{\mathbbm 1}
\newcommand{\F}{\mathcal F}
\newcommand{\E}{\mathbb E}
\newcommand{\BPeer}{\BR_\text{peer}}
\newcommand{\lPeer}{\ell_{\text{peer}}}
\newcommand{\AlphaPeer}{\BR_\text{$\alpha$-peer}}
\newcommand{\AlphaStar}{\BR_\text{$\alpha^*$-peer}}
\newcommand{\trans}{\text{T}}

\newcommand{\lAlphaPeer}{\ell_\text{$\alpha$-peer}}
\newcommand{\lAlphaStar}{\ell_\text{$\alpha^*$-peer}}

\newcommand{\squishlist}{
\begin{list}{{{\small{$\bullet$}}}}
{\setlength{\itemsep}{3pt}      \setlength{\parsep}{1pt}
\setlength{\topsep}{1pt}       \setlength{\partopsep}{0pt}
\setlength{\leftmargin}{1em} \setlength{\labelwidth}{1em}
\setlength{\labelsep}{0.5em} } }
\newcommand{\squishend}{  \end{list}  }
\newcommand\bigzero{\makebox(0,0){\text{\large0}}}
\newcommand\Tstrut{\rule{0pt}{2.6ex}}

\ifodd 1
\newcommand{\rev}[1]{{\color{blue}#1}}
\newcommand{\yl}[1]{\textbf{\color{red}(Yang: #1)}}
\newcommand{\zzw}[2]{\textbf{\color{blue}(Zhaowei: #1)}{\color{blue}#2}}
\newcommand{\lxy}[1]{\textbf{\color{blue}(Xingyu: #1)}}

\newcommand{\clar}[1]{\textbf{\color{green}(NEED CLARIFICATION: #1)}}
\newcommand{\response}[1]{\textbf{\color{magenta}(RESPONSE: #1)}}
\else
\newcommand{\rev}[1]{#1}
\newcommand{\com}[1]{}
\newcommand{\clar}[1]{}
\newcommand{\response}[1]{}
\fi
\newtheorem{thm}{Theorem}
\newtheorem{prop}{Proposition}
\newtheorem{lem}{Lemma}
\newtheorem{cor}{Corollary}

\newtheorem{innercustomlem}{Lemma}
\newenvironment{customlem}[1]
  {\renewcommand\theinnercustomlem{#1}\innercustomlem}
  {\endinnercustomlem}
  
\newtheorem{innercustomthm}{Theorem}
\newenvironment{customthm}[1]
  {\renewcommand\theinnercustomthm{#1}\innercustomthm}
  {\endinnercustomthm}


\title{CSE142 Project 1-page Proposal Template}
\author{Group member}
\begin{document}
\maketitle
\section{Project Idea}
Briefly describe the project background/influences, your aim/ideas of this project.   \\
\textbf{An example:}\\
Deep-Fake technique is a kind of synthetic media where a person in an already existed video (or image) is substituted by someone else's likeness \cite{wiki}. With the help of machine learning algorithms like Generative Adversarial Networks, a fake (AI-generated) video appears just like a real one. Deep-Fake techniques have a crucial impact on how people determine the legitimacy of information presented online. What is more, the quality of public discourse and the protection of human rights are confronted with severe challenge given that Deep-Fake techniques have been used maliciously as a source of persuasion, harassment, etc  \cite{kaggle}. Detecting fake media is in technically demand. Our aim is to build innovative new technologies that can help detect Deep-Fake related manipulated media.


\section{Dataset Description}
Provide a brief description of the training dataset.\\
\textbf{An example:}\\
The whole training dataset is available here \cite{Data}. The corresponding data size is approximately 470 GB. The original dataset is comprised of .mp4 files and has been split into 50 smaller chunks. Each .mp4 file is a 10-second video with a person speaking aloud. A metadata.json accompanies each chunk of .mp4 files. 3 columns are included in each .json file:
\begin{itemize}
  \item \textbf{filename}: the filename of the corresponding video
  \item \textbf{label}: REAL (real videos) or FAKE (AI-generated videos)
  \item  \textbf{original}: if the train set video is FAKE, the original video is provided here
\end{itemize}

\section{Input-Output Behavior}
What are the input and output of your machine learning algorithms?   \\
\textbf{An example:}\\
This training dataset is prohibitively large to train directly. Thus, we decide to extract some useful information from these smaller chunks, for example, for each video, we are interested in extracting about 10 frames and also the audio part of this video. We will train our designed model on these two major parts instead. At the beginning, we would like to train our model on extracted images (the \textbf{Input}). In the prediction stage, the model will provide us with predicted probability of the video being FAKE (the \textbf{Output}). 



\section{Evaluation Metrics}
The metric (accuracy score) of evaluating your machine learning algorithms.  \\
\textbf{An example:}\\
\begin{equation}
    LogLoss = \frac{-1}{n}\sum_{i=1}^{n}[y_ilog(\hat{y_i})+(1-y_i)log(1-\hat{y_i})]
\end{equation}
Here, $n$ is the number of videos being predicted. $\hat{y_i}$ is the predicted probability of the video being FAKE. $y_i$ is $1$ if the video is FAKE, $0$ if REAL. $log()$ is the natural algorithm with base $e$.


The use of logarithm will punish the case of being both confident and wrong. In some extreme cases, for example, a prediction that something is true when it is actually false, the value of $y_ilog(\hat{y_i})+(1-y_i)log(1-\hat{y_i})$ will be infinity. Thus, the predicted probabilities should have a upper bound and a lower bound in order to prevent these extreme cases. In a nutshell, the smaller loss means the better performance. 


\begin{thebibliography}{9}
\bibitem{wiki}
https://en.wikipedia.org/wiki/Deepfake

\bibitem{kaggle}
https://www.kaggle.com/c/deepfake-detection-challenge/overview

\bibitem{Data}
https://www.kaggle.com/c/deepfake-detection-challenge/data

\end{thebibliography}


\end{document}
